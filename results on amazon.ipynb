{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9adcbbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "dataset_path = 'AMZNclass_data.csv'\n",
    "df = pd.read_csv('AMZNclass_data.csv')\n",
    "\n",
    "# Extract dataset name from the file path\n",
    "dataset_name = dataset_path.split('/')[-1].split('.')[0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "814e029f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MACD</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MA</th>\n",
       "      <th>EMA</th>\n",
       "      <th>SMA</th>\n",
       "      <th>STD</th>\n",
       "      <th>Upper</th>\n",
       "      <th>Lower</th>\n",
       "      <th>PatternClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>4.075000</td>\n",
       "      <td>4.478125</td>\n",
       "      <td>3.952344</td>\n",
       "      <td>4.468750</td>\n",
       "      <td>322352000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>3.565625</td>\n",
       "      <td>3.634375</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.278125</td>\n",
       "      <td>375040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.382812</td>\n",
       "      <td>3.436285</td>\n",
       "      <td>3.382812</td>\n",
       "      <td>0.104687</td>\n",
       "      <td>3.592187</td>\n",
       "      <td>3.173438</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>3.350000</td>\n",
       "      <td>3.525000</td>\n",
       "      <td>3.309375</td>\n",
       "      <td>3.478125</td>\n",
       "      <td>210108000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.363644</td>\n",
       "      <td>3.378125</td>\n",
       "      <td>3.464178</td>\n",
       "      <td>3.378125</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.578125</td>\n",
       "      <td>3.178125</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>3.628125</td>\n",
       "      <td>3.631250</td>\n",
       "      <td>3.278125</td>\n",
       "      <td>3.459375</td>\n",
       "      <td>295158000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.042539</td>\n",
       "      <td>3.468750</td>\n",
       "      <td>3.460976</td>\n",
       "      <td>3.468750</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>3.487500</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-12</td>\n",
       "      <td>3.393750</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>3.178125</td>\n",
       "      <td>216090000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.510636</td>\n",
       "      <td>3.257812</td>\n",
       "      <td>3.244970</td>\n",
       "      <td>3.257812</td>\n",
       "      <td>0.079688</td>\n",
       "      <td>3.417188</td>\n",
       "      <td>3.098437</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>85.519997</td>\n",
       "      <td>85.680000</td>\n",
       "      <td>82.250000</td>\n",
       "      <td>83.790001</td>\n",
       "      <td>81431300</td>\n",
       "      <td>-3.342859</td>\n",
       "      <td>20.097895</td>\n",
       "      <td>85.279999</td>\n",
       "      <td>84.640855</td>\n",
       "      <td>85.279999</td>\n",
       "      <td>1.489998</td>\n",
       "      <td>88.259995</td>\n",
       "      <td>82.300003</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3371</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>83.250000</td>\n",
       "      <td>85.779999</td>\n",
       "      <td>82.930000</td>\n",
       "      <td>85.250000</td>\n",
       "      <td>57433700</td>\n",
       "      <td>-3.312041</td>\n",
       "      <td>52.056891</td>\n",
       "      <td>84.520000</td>\n",
       "      <td>85.046952</td>\n",
       "      <td>84.520000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>85.980000</td>\n",
       "      <td>83.060001</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>84.970001</td>\n",
       "      <td>85.349998</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.040001</td>\n",
       "      <td>57284000</td>\n",
       "      <td>-3.426447</td>\n",
       "      <td>23.545680</td>\n",
       "      <td>84.145000</td>\n",
       "      <td>83.708984</td>\n",
       "      <td>84.145000</td>\n",
       "      <td>1.105000</td>\n",
       "      <td>86.355000</td>\n",
       "      <td>81.935001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>82.870003</td>\n",
       "      <td>84.550003</td>\n",
       "      <td>82.550003</td>\n",
       "      <td>84.180000</td>\n",
       "      <td>54995900</td>\n",
       "      <td>-3.461244</td>\n",
       "      <td>65.284476</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.603221</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>85.360001</td>\n",
       "      <td>80.639999</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>83.120003</td>\n",
       "      <td>84.050003</td>\n",
       "      <td>82.470001</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>62401200</td>\n",
       "      <td>-3.347538</td>\n",
       "      <td>59.867639</td>\n",
       "      <td>84.090000</td>\n",
       "      <td>83.867740</td>\n",
       "      <td>84.090000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>84.270000</td>\n",
       "      <td>83.910000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3375 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Open       High        Low      Close     Volume  \\\n",
       "0     2000-01-03   4.075000   4.478125   3.952344   4.468750  322352000   \n",
       "1     2000-01-06   3.565625   3.634375   3.200000   3.278125  375040000   \n",
       "2     2000-01-07   3.350000   3.525000   3.309375   3.478125  210108000   \n",
       "3     2000-01-10   3.628125   3.631250   3.278125   3.459375  295158000   \n",
       "4     2000-01-12   3.393750   3.400000   3.150000   3.178125  216090000   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "3370  2022-12-22  85.519997  85.680000  82.250000  83.790001   81431300   \n",
       "3371  2022-12-23  83.250000  85.779999  82.930000  85.250000   57433700   \n",
       "3372  2022-12-27  84.970001  85.349998  83.000000  83.040001   57284000   \n",
       "3373  2022-12-29  82.870003  84.550003  82.550003  84.180000   54995900   \n",
       "3374  2022-12-30  83.120003  84.050003  82.470001  84.000000   62401200   \n",
       "\n",
       "          MACD        RSI         MA        EMA        SMA       STD  \\\n",
       "0          NaN        NaN        NaN        NaN        NaN       NaN   \n",
       "1          NaN   0.000000   3.382812   3.436285   3.382812  0.104687   \n",
       "2          NaN  36.363644   3.378125   3.464178   3.378125  0.100000   \n",
       "3          NaN  34.042539   3.468750   3.460976   3.468750  0.009375   \n",
       "4          NaN   8.510636   3.257812   3.244970   3.257812  0.079688   \n",
       "...        ...        ...        ...        ...        ...       ...   \n",
       "3370 -3.342859  20.097895  85.279999  84.640855  85.279999  1.489998   \n",
       "3371 -3.312041  52.056891  84.520000  85.046952  84.520000  0.730000   \n",
       "3372 -3.426447  23.545680  84.145000  83.708984  84.145000  1.105000   \n",
       "3373 -3.461244  65.284476  83.000000  83.603221  83.000000  1.180000   \n",
       "3374 -3.347538  59.867639  84.090000  83.867740  84.090000  0.090000   \n",
       "\n",
       "          Upper      Lower  PatternClass  \n",
       "0           NaN        NaN             6  \n",
       "1      3.592187   3.173438             4  \n",
       "2      3.578125   3.178125             6  \n",
       "3      3.487500   3.450000             4  \n",
       "4      3.417188   3.098437             4  \n",
       "...         ...        ...           ...  \n",
       "3370  88.259995  82.300003             4  \n",
       "3371  85.980000  83.060001             6  \n",
       "3372  86.355000  81.935001             4  \n",
       "3373  85.360001  80.639999             6  \n",
       "3374  84.270000  83.910000             6  \n",
       "\n",
       "[3375 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73deed32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PatternClass', 'Open', 'High', 'Low', 'Close', 'Volume'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3700\\1011279392.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3700\\1011279392.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3700\\1011279392.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3700\\1011279392.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3700\\1011279392.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3700\\1011279392.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: AMZNclass_data\n",
      "\n",
      "            Classifier  Accuracy  F1 Score  Precision    Recall\n",
      "0        Random Forest  0.997038  0.996831   0.997056  0.997038\n",
      "1                  SVM  1.000000  1.000000   1.000000  1.000000\n",
      "2  Logistic Regression  1.000000  1.000000   1.000000  1.000000\n",
      "3        Decision Tree  1.000000  1.000000   1.000000  1.000000\n",
      "4                  KNN  0.998026  0.997937   0.998030  0.998026\n",
      "5          Naive Bayes  1.000000  1.000000   1.000000  1.000000\n",
      "6          Extra Trees  1.000000  1.000000   1.000000  1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3700\\1011279392.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your OHLC dataset with indicators\n",
    "# Replace 'your_dataset.csv' with the actual file path or DataFrame variable\n",
    "\n",
    "\n",
    "# Assuming 'PatternClass' column is already defined in your dataset\n",
    "\n",
    "# Remove rows where PatternClass is 0 (No Pattern)\n",
    "df = df[df['PatternClass'] != 0]\n",
    "\n",
    "# Convert 'Date' to datetime and extract relevant features\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "\n",
    "# Select features (X) and target variable (y)\n",
    "X = df.drop(['PatternClass', 'Date', 'Open', 'High', 'Low', 'Close'], axis=1)\n",
    "selected_features = ['PatternClass', 'Open', 'High', 'Low', 'Close','Volume']  # Replace with your actual feature names\n",
    "X = df[selected_features]\n",
    "y = df['PatternClass']\n",
    "print(X.columns)\n",
    "\n",
    "# Handle missing values by filling with mean\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Check for and handle infinite values\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X = X.fillna(0)  # You can customize the filling strategy based on your data\n",
    "\n",
    "# Encode any categorical variables if necessary\n",
    "label_encoder = LabelEncoder()\n",
    "X_encoded = X.apply(lambda col: label_encoder.fit_transform(col.astype(str)) if col.dtype == 'O' else col)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=2)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the classifiers\n",
    "rf_classifier = RandomForestClassifier(random_state=100, n_estimators=100)\n",
    "svm_classifier = SVC(random_state=100)\n",
    "logreg_classifier = LogisticRegression(random_state=100)\n",
    "dt_classifier = DecisionTreeClassifier(random_state=100)\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "nb_classifier = GaussianNB()\n",
    "extra_trees_classifier = ExtraTreesClassifier(random_state=100, n_estimators=100)  # Added Extra Trees Classifier\n",
    "\n",
    "# List of classifiers\n",
    "classifiers = [rf_classifier, svm_classifier, logreg_classifier, dt_classifier, knn_classifier, nb_classifier, extra_trees_classifier]\n",
    "classifier_names = ['Random Forest', 'SVM', 'Logistic Regression', 'Decision Tree', 'KNN', 'Naive Bayes', 'Extra Trees']\n",
    "\n",
    "# Initialize DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['Classifier', 'Accuracy', 'F1 Score'])\n",
    "\n",
    "# Loop through each classifier\n",
    "for classifier, classifier_name in zip(classifiers, classifier_names):\n",
    "    # Train the classifier\n",
    "    classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = classifier.predict(X_test_scaled)\n",
    "\n",
    "     # Evaluate the classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Append results to the DataFrame\n",
    "    results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n",
    "\n",
    "# Display the results and name of dataset\n",
    "print(f\"Dataset Name: {dataset_name}\")\n",
    "print()\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc6aec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'MACD', 'RSI', 'MA', 'EMA',\n",
      "       'SMA', 'STD', 'Upper', 'Lower', 'Year', 'Month', 'Day'],\n",
      "      dtype='object')\n",
      "SVM Metrics:\n",
      "Accuracy: 0.824284304047384\n",
      "F1 Score: 0.8143931634554755\n",
      "Confusion Matrix:\n",
      " [[  0   6   0   6]\n",
      " [  0 409   0  91]\n",
      " [  0   3   0   9]\n",
      " [  0  63   0 426]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load your OHLC dataset with indicators\n",
    "# Replace 'your_dataset.csv' with the actual file path or DataFrame variable\n",
    "\n",
    "\n",
    "# Assuming 'PatternClass' column is already defined in your dataset\n",
    "\n",
    "# Remove rows where PatternClass is 0 (No Pattern)\n",
    "df = df[df['PatternClass'] != 0]\n",
    "\n",
    "# Convert 'Date' to datetime and extract relevant features\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "\n",
    "# Select features (X) and target variable (y)\n",
    "X = df.drop(['PatternClass', 'Date'], axis=1)  # Adjust columns accordingly\n",
    "y = df['PatternClass']\n",
    "print(X.columns)\n",
    "# Handle missing values by filling with mean\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Check for and handle infinite values\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X = X.fillna(0)  # You can customize the filling strategy based on your data\n",
    "\n",
    "# Encode any categorical variables if necessary\n",
    "label_encoder = LabelEncoder()\n",
    "X_encoded = X.apply(lambda col: label_encoder.fit_transform(col.astype(str)) if col.dtype == 'O' else col)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=2)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(f\"{model_name} Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the Support Vector Machine (SVM) Classifier\n",
    "svm_classifier = SVC(random_state=100)\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using SVM\n",
    "y_pred_svm = svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "evaluate_model(y_test, y_pred_svm, \"SVM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82217f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Metrics:\n",
      "Accuracy: 0.7591312931885489\n",
      "F1 Score: 0.7604589877760766\n",
      "Confusion Matrix:\n",
      " [[  1   0   6   0   5]\n",
      " [  0   0   0   0   0]\n",
      " [  0   1 383  16 100]\n",
      " [  0   0   5   0   7]\n",
      " [  2   0  96   6 385]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=100)\n",
    "\n",
    "# Train the Decision Tree classifier\n",
    "dt_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using Decision Tree\n",
    "y_pred_dt = dt_classifier.predict(X_test_scaled)\n",
    "\n",
    "## Evaluate the Decision Tree model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt, average='weighted')\n",
    "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "\n",
    "print(\"\\nDecision Tree Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(\"F1 Score:\", f1_dt)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfe00d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'MACD', 'RSI', 'MA', 'EMA',\n",
      "       'SMA', 'STD', 'Upper', 'Lower', 'Year', 'Month', 'Day'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cb28235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.8193484698914116\n",
      "F1 Score: 0.8095933283147387\n",
      "Confusion Matrix:\n",
      " [[  0   6   0   6]\n",
      " [  0 414   0  86]\n",
      " [  0   1   0  11]\n",
      " [  0  73   0 416]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Initialize the Logistic Regression Classifier\n",
    "logreg_classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the Logistic Regression classifier\n",
    "logreg_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using Logistic Regression\n",
    "y_pred_logreg = logreg_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the Logistic Regression model\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "f1_logreg = f1_score(y_test, y_pred_logreg, average='weighted')\n",
    "conf_matrix_logreg = confusion_matrix(y_test, y_pred_logreg)\n",
    "\n",
    "print(\"\\nLogistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_logreg)\n",
    "print(\"F1 Score:\", f1_logreg)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fa62179b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'MACD', 'RSI', 'MA', 'EMA',\n",
      "       'SMA', 'STD', 'Upper', 'Lower', 'Year', 'Month', 'Day'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "116a8776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Nearest Neighbors Metrics:\n",
      "Accuracy: 0.790720631786772\n",
      "F1 Score: 0.7812747400499447\n",
      "Confusion Matrix:\n",
      " [[  0   7   0   5]\n",
      " [  0 401   0  99]\n",
      " [  0   2   0  10]\n",
      " [  0  89   0 400]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the K-Nearest Neighbors Classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Train the KNN classifier\n",
    "knn_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using KNN\n",
    "y_pred_knn = knn_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the KNN model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_knn)\n",
    "print(\"F1 Score:\", f1_knn)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4b140dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Metrics:\n",
      "Accuracy: 0.6209279368213229\n",
      "F1 Score: 0.6779381019153647\n",
      "Confusion Matrix:\n",
      " [[  8   0   0   4]\n",
      " [135 288   0  77]\n",
      " [  4   1   0   7]\n",
      " [ 67  89   0 333]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Naive Bayes Classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "nb_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using Naive Bayes\n",
    "y_pred_nb = nb_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the Naive Bayes model\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "f1_nb = f1_score(y_test, y_pred_nb, average='weighted')\n",
    "conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "\n",
    "print(\"\\nNaive Bayes Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_nb)\n",
    "print(\"F1 Score:\", f1_nb)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a35d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3fd10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6540f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
