{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca9212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GraphConv  # Import GraphConv\n",
    "from torch.optim import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6235b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd6c787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MACD</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MA</th>\n",
       "      <th>EMA</th>\n",
       "      <th>SMA</th>\n",
       "      <th>STD</th>\n",
       "      <th>Upper</th>\n",
       "      <th>Lower</th>\n",
       "      <th>numeric_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/13/2018</td>\n",
       "      <td>48.105000</td>\n",
       "      <td>48.220001</td>\n",
       "      <td>47.610001</td>\n",
       "      <td>47.674999</td>\n",
       "      <td>45.561813</td>\n",
       "      <td>86553600</td>\n",
       "      <td>0.343733</td>\n",
       "      <td>57.884069</td>\n",
       "      <td>47.404500</td>\n",
       "      <td>47.518221</td>\n",
       "      <td>47.404500</td>\n",
       "      <td>0.621977</td>\n",
       "      <td>48.648453</td>\n",
       "      <td>46.160546</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/14/2018</td>\n",
       "      <td>47.887501</td>\n",
       "      <td>47.892502</td>\n",
       "      <td>47.555000</td>\n",
       "      <td>47.700001</td>\n",
       "      <td>45.585709</td>\n",
       "      <td>86440400</td>\n",
       "      <td>0.315295</td>\n",
       "      <td>58.995271</td>\n",
       "      <td>47.437250</td>\n",
       "      <td>47.535534</td>\n",
       "      <td>47.437250</td>\n",
       "      <td>0.619290</td>\n",
       "      <td>48.675829</td>\n",
       "      <td>46.198670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/15/2018</td>\n",
       "      <td>47.507500</td>\n",
       "      <td>47.540001</td>\n",
       "      <td>47.064999</td>\n",
       "      <td>47.209999</td>\n",
       "      <td>45.117435</td>\n",
       "      <td>246876800</td>\n",
       "      <td>0.250333</td>\n",
       "      <td>50.799494</td>\n",
       "      <td>47.460375</td>\n",
       "      <td>47.504530</td>\n",
       "      <td>47.460375</td>\n",
       "      <td>0.600529</td>\n",
       "      <td>48.661433</td>\n",
       "      <td>46.259316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/18/2018</td>\n",
       "      <td>46.970001</td>\n",
       "      <td>47.305000</td>\n",
       "      <td>46.799999</td>\n",
       "      <td>47.185001</td>\n",
       "      <td>45.093540</td>\n",
       "      <td>73939600</td>\n",
       "      <td>0.194590</td>\n",
       "      <td>52.678608</td>\n",
       "      <td>47.490750</td>\n",
       "      <td>47.474099</td>\n",
       "      <td>47.490750</td>\n",
       "      <td>0.568006</td>\n",
       "      <td>48.626761</td>\n",
       "      <td>46.354739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/19/2018</td>\n",
       "      <td>46.285000</td>\n",
       "      <td>46.582500</td>\n",
       "      <td>45.862499</td>\n",
       "      <td>46.422501</td>\n",
       "      <td>44.364834</td>\n",
       "      <td>134314000</td>\n",
       "      <td>0.087873</td>\n",
       "      <td>45.062755</td>\n",
       "      <td>47.466500</td>\n",
       "      <td>47.373947</td>\n",
       "      <td>47.466500</td>\n",
       "      <td>0.603463</td>\n",
       "      <td>48.673427</td>\n",
       "      <td>46.259573</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>05-08-2023</td>\n",
       "      <td>172.479996</td>\n",
       "      <td>173.850006</td>\n",
       "      <td>172.110001</td>\n",
       "      <td>173.500000</td>\n",
       "      <td>173.260345</td>\n",
       "      <td>55962800</td>\n",
       "      <td>2.895528</td>\n",
       "      <td>65.079344</td>\n",
       "      <td>166.603000</td>\n",
       "      <td>166.920041</td>\n",
       "      <td>166.603000</td>\n",
       "      <td>3.441849</td>\n",
       "      <td>173.486697</td>\n",
       "      <td>159.719302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>05-09-2023</td>\n",
       "      <td>173.050003</td>\n",
       "      <td>173.539993</td>\n",
       "      <td>171.600006</td>\n",
       "      <td>171.770004</td>\n",
       "      <td>171.532745</td>\n",
       "      <td>45326900</td>\n",
       "      <td>2.933239</td>\n",
       "      <td>58.668332</td>\n",
       "      <td>167.151500</td>\n",
       "      <td>167.381942</td>\n",
       "      <td>167.151500</td>\n",
       "      <td>3.341023</td>\n",
       "      <td>173.833546</td>\n",
       "      <td>160.469454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>05-10-2023</td>\n",
       "      <td>173.020004</td>\n",
       "      <td>174.029999</td>\n",
       "      <td>171.899994</td>\n",
       "      <td>173.559998</td>\n",
       "      <td>173.320267</td>\n",
       "      <td>53724500</td>\n",
       "      <td>3.072149</td>\n",
       "      <td>63.993525</td>\n",
       "      <td>167.824500</td>\n",
       "      <td>167.970328</td>\n",
       "      <td>167.824500</td>\n",
       "      <td>3.198461</td>\n",
       "      <td>174.221422</td>\n",
       "      <td>161.427577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>05-11-2023</td>\n",
       "      <td>173.850006</td>\n",
       "      <td>174.589996</td>\n",
       "      <td>172.169998</td>\n",
       "      <td>173.750000</td>\n",
       "      <td>173.510010</td>\n",
       "      <td>49514700</td>\n",
       "      <td>3.161129</td>\n",
       "      <td>68.774172</td>\n",
       "      <td>168.234000</td>\n",
       "      <td>168.520773</td>\n",
       "      <td>168.234000</td>\n",
       "      <td>3.410531</td>\n",
       "      <td>175.055062</td>\n",
       "      <td>161.412937</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>05-12-2023</td>\n",
       "      <td>173.619995</td>\n",
       "      <td>174.059998</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>172.570007</td>\n",
       "      <td>172.570007</td>\n",
       "      <td>45497800</td>\n",
       "      <td>3.100687</td>\n",
       "      <td>65.008295</td>\n",
       "      <td>168.602000</td>\n",
       "      <td>168.906415</td>\n",
       "      <td>168.602000</td>\n",
       "      <td>3.463727</td>\n",
       "      <td>175.529453</td>\n",
       "      <td>161.674546</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1238 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "0      6/13/2018   48.105000   48.220001   47.610001   47.674999   45.561813   \n",
       "1      6/14/2018   47.887501   47.892502   47.555000   47.700001   45.585709   \n",
       "2      6/15/2018   47.507500   47.540001   47.064999   47.209999   45.117435   \n",
       "3      6/18/2018   46.970001   47.305000   46.799999   47.185001   45.093540   \n",
       "4      6/19/2018   46.285000   46.582500   45.862499   46.422501   44.364834   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1233  05-08-2023  172.479996  173.850006  172.110001  173.500000  173.260345   \n",
       "1234  05-09-2023  173.050003  173.539993  171.600006  171.770004  171.532745   \n",
       "1235  05-10-2023  173.020004  174.029999  171.899994  173.559998  173.320267   \n",
       "1236  05-11-2023  173.850006  174.589996  172.169998  173.750000  173.510010   \n",
       "1237  05-12-2023  173.619995  174.059998  171.000000  172.570007  172.570007   \n",
       "\n",
       "         Volume      MACD        RSI          MA         EMA         SMA  \\\n",
       "0      86553600  0.343733  57.884069   47.404500   47.518221   47.404500   \n",
       "1      86440400  0.315295  58.995271   47.437250   47.535534   47.437250   \n",
       "2     246876800  0.250333  50.799494   47.460375   47.504530   47.460375   \n",
       "3      73939600  0.194590  52.678608   47.490750   47.474099   47.490750   \n",
       "4     134314000  0.087873  45.062755   47.466500   47.373947   47.466500   \n",
       "...         ...       ...        ...         ...         ...         ...   \n",
       "1233   55962800  2.895528  65.079344  166.603000  166.920041  166.603000   \n",
       "1234   45326900  2.933239  58.668332  167.151500  167.381942  167.151500   \n",
       "1235   53724500  3.072149  63.993525  167.824500  167.970328  167.824500   \n",
       "1236   49514700  3.161129  68.774172  168.234000  168.520773  168.234000   \n",
       "1237   45497800  3.100687  65.008295  168.602000  168.906415  168.602000   \n",
       "\n",
       "           STD       Upper       Lower  numeric_classes  \n",
       "0     0.621977   48.648453   46.160546                4  \n",
       "1     0.619290   48.675829   46.198670                0  \n",
       "2     0.600529   48.661433   46.259316                0  \n",
       "3     0.568006   48.626761   46.354739                0  \n",
       "4     0.603463   48.673427   46.259573                2  \n",
       "...        ...         ...         ...              ...  \n",
       "1233  3.441849  173.486697  159.719302                0  \n",
       "1234  3.341023  173.833546  160.469454                0  \n",
       "1235  3.198461  174.221422  161.427577                0  \n",
       "1236  3.410531  175.055062  161.412937                3  \n",
       "1237  3.463727  175.529453  161.674546                0  \n",
       "\n",
       "[1238 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "917131ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df559f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, sequence_length):\n",
    "    data = data[['Open', 'High', 'Low', 'Close']].values\n",
    "    scaler = MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i+sequence_length])\n",
    "        y.append(data[i+sequence_length])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af0645ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = prepare_data(df, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2640b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0464511a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.82555324, 0.84342365, 0.82829697, 0.84692327],\n",
       "        [0.83619188, 0.85024912, 0.85036909, 0.85395578]],\n",
       "\n",
       "       [[0.26572782, 0.26479419, 0.27064479, 0.26662118],\n",
       "        [0.26115866, 0.27083476, 0.27008775, 0.27481438]],\n",
       "\n",
       "       [[0.73171473, 0.75162106, 0.7504526 , 0.75652477],\n",
       "        [0.74514946, 0.75844653, 0.76242866, 0.76123579]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.72421317, 0.729916  , 0.72761456, 0.71958696],\n",
       "        [0.72537251, 0.73093988, 0.73527371, 0.73126225]],\n",
       "\n",
       "       [[0.77761108, 0.77605627, 0.78227273, 0.76724419],\n",
       "        [0.77038226, 0.77127835, 0.78108896, 0.76690278]],\n",
       "\n",
       "       [[0.76526752, 0.76923079, 0.7736388 , 0.76990698],\n",
       "        [0.7499233 , 0.76151797, 0.76695445, 0.76649314]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eced324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.09486139, 0.09611972, 0.09948126, 0.09949645],\n",
       "        [0.09724828, 0.11333697, 0.1017964 , 0.11398822]],\n",
       "\n",
       "       [[0.5894568 , 0.58924306, 0.59218776, 0.59306994],\n",
       "        [0.59061612, 0.59327006, 0.59908094, 0.58876847]],\n",
       "\n",
       "       [[0.82739457, 0.83932832, 0.84277954, 0.84480671],\n",
       "        [0.84089746, 0.85803015, 0.85162235, 0.83490659]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.2072493 , 0.20537845, 0.20609942, 0.20653752],\n",
       "        [0.20409521, 0.2018463 , 0.20745717, 0.20452336]],\n",
       "\n",
       "       [[0.55017558, 0.56159988, 0.56364016, 0.55524455],\n",
       "        [0.5554949 , 0.55702682, 0.55068931, 0.54759752]],\n",
       "\n",
       "       [[0.76519926, 0.82635996, 0.78206386, 0.82063674],\n",
       "        [0.79902479, 0.80410896, 0.81061135, 0.80425023]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4019a43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be886fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.FloatTensor(y_train).view(-1, 1, 4)  # Reshape y_train\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.FloatTensor(y_test).view(-1, 1, 4)  # Reshape y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0266466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8256, 0.8434, 0.8283, 0.8469],\n",
       "         [0.8362, 0.8502, 0.8504, 0.8540]],\n",
       "\n",
       "        [[0.2657, 0.2648, 0.2706, 0.2666],\n",
       "         [0.2612, 0.2708, 0.2701, 0.2748]],\n",
       "\n",
       "        [[0.7317, 0.7516, 0.7505, 0.7565],\n",
       "         [0.7451, 0.7584, 0.7624, 0.7612]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7242, 0.7299, 0.7276, 0.7196],\n",
       "         [0.7254, 0.7309, 0.7353, 0.7313]],\n",
       "\n",
       "        [[0.7776, 0.7761, 0.7823, 0.7672],\n",
       "         [0.7704, 0.7713, 0.7811, 0.7669]],\n",
       "\n",
       "        [[0.7653, 0.7692, 0.7736, 0.7699],\n",
       "         [0.7499, 0.7615, 0.7670, 0.7665]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e418fce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0949, 0.0961, 0.0995, 0.0995],\n",
       "         [0.0972, 0.1133, 0.1018, 0.1140]],\n",
       "\n",
       "        [[0.5895, 0.5892, 0.5922, 0.5931],\n",
       "         [0.5906, 0.5933, 0.5991, 0.5888]],\n",
       "\n",
       "        [[0.8274, 0.8393, 0.8428, 0.8448],\n",
       "         [0.8409, 0.8580, 0.8516, 0.8349]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2072, 0.2054, 0.2061, 0.2065],\n",
       "         [0.2041, 0.2018, 0.2075, 0.2045]],\n",
       "\n",
       "        [[0.5502, 0.5616, 0.5636, 0.5552],\n",
       "         [0.5555, 0.5570, 0.5507, 0.5476]],\n",
       "\n",
       "        [[0.7652, 0.8264, 0.7821, 0.8206],\n",
       "         [0.7990, 0.8041, 0.8106, 0.8043]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ad4d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphConvModel, self).__init__()\n",
    "        self.conv1 = GraphConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "887676d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = sequence_length\n",
    "edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes) if i != j], dtype=torch.long).t().contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af699702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60a57ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "114d8817",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphConvModel(in_channels=4, hidden_channels=8, out_channels=4)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75952df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_2344\\502600674.py:7: UserWarning: Using a target size (torch.Size([988, 1, 4])) that is different to the input size (torch.Size([988, 2, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(out, y_train_reshaped)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(X_train, edge_index)\n",
    "    # Reshape the target labels to match the model's output shape\n",
    "    y_train_reshaped = y_train.view(-1, 1, 4)\n",
    "    loss = F.mse_loss(out, y_train_reshaped)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fc3474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "396c6abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([248, 2, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96bb18c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([248, 1, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e14ec65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test set: 0.2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_2344\\1804030440.py:1: UserWarning: Using a target size (torch.Size([248, 1, 4])) that is different to the input size (torch.Size([248, 2, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  rmse = torch.sqrt(F.mse_loss(y_pred, y_test))\n"
     ]
    }
   ],
   "source": [
    "rmse = torch.sqrt(F.mse_loss(y_pred, y_test))\n",
    "print(f'RMSE on the test set: {rmse.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7326fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
