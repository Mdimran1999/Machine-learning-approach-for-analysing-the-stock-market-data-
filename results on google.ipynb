{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0dcbabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "dataset_path = 'GOOGLclass_data.csv'\n",
    "df = pd.read_csv('GOOGLclass_data.csv')\n",
    "\n",
    "# Extract dataset name from the file path\n",
    "dataset_name = dataset_path.split('/')[-1].split('.')[0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7503e508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MACD</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MA</th>\n",
       "      <th>EMA</th>\n",
       "      <th>SMA</th>\n",
       "      <th>STD</th>\n",
       "      <th>Upper</th>\n",
       "      <th>Lower</th>\n",
       "      <th>PatternClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-08-20</td>\n",
       "      <td>2.527778</td>\n",
       "      <td>2.729730</td>\n",
       "      <td>2.515015</td>\n",
       "      <td>2.710460</td>\n",
       "      <td>2.710460</td>\n",
       "      <td>456686856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.610735</td>\n",
       "      <td>2.610735</td>\n",
       "      <td>2.610735</td>\n",
       "      <td>0.099725</td>\n",
       "      <td>2.810184</td>\n",
       "      <td>2.411286</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-08-24</td>\n",
       "      <td>2.783784</td>\n",
       "      <td>2.792793</td>\n",
       "      <td>2.591842</td>\n",
       "      <td>2.624374</td>\n",
       "      <td>2.624374</td>\n",
       "      <td>304946748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.999895</td>\n",
       "      <td>2.681056</td>\n",
       "      <td>2.648051</td>\n",
       "      <td>2.681056</td>\n",
       "      <td>0.056682</td>\n",
       "      <td>2.794420</td>\n",
       "      <td>2.567692</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-08-26</td>\n",
       "      <td>2.626376</td>\n",
       "      <td>2.701451</td>\n",
       "      <td>2.619119</td>\n",
       "      <td>2.700450</td>\n",
       "      <td>2.700450</td>\n",
       "      <td>141897960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.107414</td>\n",
       "      <td>2.676551</td>\n",
       "      <td>2.684006</td>\n",
       "      <td>2.676551</td>\n",
       "      <td>0.023898</td>\n",
       "      <td>2.724348</td>\n",
       "      <td>2.628754</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-08-27</td>\n",
       "      <td>2.705205</td>\n",
       "      <td>2.718218</td>\n",
       "      <td>2.644895</td>\n",
       "      <td>2.656406</td>\n",
       "      <td>2.656406</td>\n",
       "      <td>124235640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.674203</td>\n",
       "      <td>2.678428</td>\n",
       "      <td>2.665606</td>\n",
       "      <td>2.678428</td>\n",
       "      <td>0.022022</td>\n",
       "      <td>2.722472</td>\n",
       "      <td>2.634384</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-08-30</td>\n",
       "      <td>2.634635</td>\n",
       "      <td>2.639890</td>\n",
       "      <td>2.552803</td>\n",
       "      <td>2.552803</td>\n",
       "      <td>2.552803</td>\n",
       "      <td>103935960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.534659</td>\n",
       "      <td>2.604604</td>\n",
       "      <td>2.590404</td>\n",
       "      <td>2.604604</td>\n",
       "      <td>0.051801</td>\n",
       "      <td>2.708207</td>\n",
       "      <td>2.501002</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>88.160004</td>\n",
       "      <td>88.540001</td>\n",
       "      <td>86.320000</td>\n",
       "      <td>87.760002</td>\n",
       "      <td>87.760002</td>\n",
       "      <td>27658300</td>\n",
       "      <td>-2.030253</td>\n",
       "      <td>16.638351</td>\n",
       "      <td>88.670002</td>\n",
       "      <td>88.313583</td>\n",
       "      <td>88.670002</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>90.490002</td>\n",
       "      <td>86.850002</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>87.110001</td>\n",
       "      <td>89.550003</td>\n",
       "      <td>87.070000</td>\n",
       "      <td>89.230003</td>\n",
       "      <td>89.230003</td>\n",
       "      <td>23003000</td>\n",
       "      <td>-2.062129</td>\n",
       "      <td>60.285579</td>\n",
       "      <td>88.495003</td>\n",
       "      <td>88.924530</td>\n",
       "      <td>88.495003</td>\n",
       "      <td>0.735001</td>\n",
       "      <td>89.965004</td>\n",
       "      <td>87.025002</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>88.800003</td>\n",
       "      <td>88.940002</td>\n",
       "      <td>87.010002</td>\n",
       "      <td>87.389999</td>\n",
       "      <td>87.389999</td>\n",
       "      <td>20097300</td>\n",
       "      <td>-2.210383</td>\n",
       "      <td>26.089129</td>\n",
       "      <td>88.310001</td>\n",
       "      <td>87.901510</td>\n",
       "      <td>88.310001</td>\n",
       "      <td>0.920002</td>\n",
       "      <td>90.150005</td>\n",
       "      <td>86.469997</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>86.620003</td>\n",
       "      <td>88.849998</td>\n",
       "      <td>86.610001</td>\n",
       "      <td>88.449997</td>\n",
       "      <td>88.449997</td>\n",
       "      <td>23333500</td>\n",
       "      <td>-2.346211</td>\n",
       "      <td>67.284891</td>\n",
       "      <td>87.234997</td>\n",
       "      <td>87.849054</td>\n",
       "      <td>87.234997</td>\n",
       "      <td>1.215000</td>\n",
       "      <td>89.664997</td>\n",
       "      <td>84.804996</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>86.980003</td>\n",
       "      <td>88.300003</td>\n",
       "      <td>86.570000</td>\n",
       "      <td>88.230003</td>\n",
       "      <td>88.230003</td>\n",
       "      <td>23986300</td>\n",
       "      <td>-2.286547</td>\n",
       "      <td>60.504099</td>\n",
       "      <td>88.340000</td>\n",
       "      <td>88.103020</td>\n",
       "      <td>88.340000</td>\n",
       "      <td>0.109997</td>\n",
       "      <td>88.559994</td>\n",
       "      <td>88.120007</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2652 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Open       High        Low      Close  Adj Close  \\\n",
       "0     2004-08-20   2.527778   2.729730   2.515015   2.710460   2.710460   \n",
       "1     2004-08-24   2.783784   2.792793   2.591842   2.624374   2.624374   \n",
       "2     2004-08-26   2.626376   2.701451   2.619119   2.700450   2.700450   \n",
       "3     2004-08-27   2.705205   2.718218   2.644895   2.656406   2.656406   \n",
       "4     2004-08-30   2.634635   2.639890   2.552803   2.552803   2.552803   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "2647  2022-12-22  88.160004  88.540001  86.320000  87.760002  87.760002   \n",
       "2648  2022-12-23  87.110001  89.550003  87.070000  89.230003  89.230003   \n",
       "2649  2022-12-27  88.800003  88.940002  87.010002  87.389999  87.389999   \n",
       "2650  2022-12-29  86.620003  88.849998  86.610001  88.449997  88.449997   \n",
       "2651  2022-12-30  86.980003  88.300003  86.570000  88.230003  88.230003   \n",
       "\n",
       "         Volume      MACD        RSI         MA        EMA        SMA  \\\n",
       "0     456686856       NaN        NaN   2.610735   2.610735   2.610735   \n",
       "1     304946748       NaN  49.999895   2.681056   2.648051   2.681056   \n",
       "2     141897960       NaN  76.107414   2.676551   2.684006   2.676551   \n",
       "3     124235640       NaN  43.674203   2.678428   2.665606   2.678428   \n",
       "4     103935960       NaN  14.534659   2.604604   2.590404   2.604604   \n",
       "...         ...       ...        ...        ...        ...        ...   \n",
       "2647   27658300 -2.030253  16.638351  88.670002  88.313583  88.670002   \n",
       "2648   23003000 -2.062129  60.285579  88.495003  88.924530  88.495003   \n",
       "2649   20097300 -2.210383  26.089129  88.310001  87.901510  88.310001   \n",
       "2650   23333500 -2.346211  67.284891  87.234997  87.849054  87.234997   \n",
       "2651   23986300 -2.286547  60.504099  88.340000  88.103020  88.340000   \n",
       "\n",
       "           STD      Upper      Lower  PatternClass  \n",
       "0     0.099725   2.810184   2.411286             6  \n",
       "1     0.056682   2.794420   2.567692             4  \n",
       "2     0.023898   2.724348   2.628754             6  \n",
       "3     0.022022   2.722472   2.634384             4  \n",
       "4     0.051801   2.708207   2.501002             4  \n",
       "...        ...        ...        ...           ...  \n",
       "2647  0.910000  90.490002  86.850002             4  \n",
       "2648  0.735001  89.965004  87.025002             6  \n",
       "2649  0.920002  90.150005  86.469997             4  \n",
       "2650  1.215000  89.664997  84.804996             6  \n",
       "2651  0.109997  88.559994  88.120007             6  \n",
       "\n",
       "[2652 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d862fc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns: Index(['PatternClass', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8532\\3765309168.py:74: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8532\\3765309168.py:74: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8532\\3765309168.py:74: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8532\\3765309168.py:74: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8532\\3765309168.py:74: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8532\\3765309168.py:74: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: GOOGLclass_data\n",
      "\n",
      "            Classifier  Accuracy  F1 Score  Precision    Recall\n",
      "0        Random Forest  0.998744  0.998116   0.997491  0.998744\n",
      "1                  SVM  1.000000  1.000000   1.000000  1.000000\n",
      "2  Logistic Regression  0.998744  0.998116   0.997491  0.998744\n",
      "3        Decision Tree  1.000000  1.000000   1.000000  1.000000\n",
      "4                  KNN  0.994975  0.994274   0.993738  0.994975\n",
      "5          Naive Bayes  1.000000  1.000000   1.000000  1.000000\n",
      "6          Extra Trees  1.000000  1.000000   1.000000  1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8532\\3765309168.py:74: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your OHLC dataset with indicators\n",
    "# Replace 'your_dataset.csv' with the actual file path or DataFrame variable\n",
    "\n",
    "\n",
    "# Assuming 'PatternClass' column is already defined in your dataset\n",
    "\n",
    "# Remove rows where PatternClass is 0 (No Pattern)\n",
    "df = df[df['PatternClass'] != 0]\n",
    "\n",
    "# Convert 'Date' to datetime and extract relevant features\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "\n",
    "# Select features (X) and target variable (y)\n",
    "X = df.drop(['PatternClass', 'Date', 'Open', 'High', 'Low', 'Close','Volume','Adj Close'], axis=1)\n",
    "selected_features = ['PatternClass', 'Open', 'High', 'Low', 'Close','Volume','Adj Close']  # Replace with your actual feature names\n",
    "X = df[selected_features]\n",
    "\n",
    "y = df['PatternClass']\n",
    "print(\"Feature Columns:\", X.columns)\n",
    "\n",
    "# Handle missing values by filling with mean\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Check for and handle infinite values\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X = X.fillna(0)  # You can customize the filling strategy based on your data\n",
    "\n",
    "# Encode any categorical variables if necessary\n",
    "label_encoder = LabelEncoder()\n",
    "X_encoded = X.apply(lambda col: label_encoder.fit_transform(col.astype(str)) if col.dtype == 'O' else col)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=2)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the classifiers\n",
    "rf_classifier = RandomForestClassifier(random_state=100, n_estimators=100)\n",
    "svm_classifier = SVC(random_state=100)\n",
    "logreg_classifier = LogisticRegression(random_state=100)\n",
    "dt_classifier = DecisionTreeClassifier(random_state=100)\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "nb_classifier = GaussianNB()\n",
    "extra_trees_classifier = ExtraTreesClassifier(random_state=100, n_estimators=100)  # Added Extra Trees Classifier\n",
    "\n",
    "# List of classifiers\n",
    "classifiers = [rf_classifier, svm_classifier, logreg_classifier, dt_classifier, knn_classifier, nb_classifier, extra_trees_classifier]\n",
    "classifier_names = ['Random Forest', 'SVM', 'Logistic Regression', 'Decision Tree', 'KNN', 'Naive Bayes', 'Extra Trees']\n",
    "\n",
    "# Initialize DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['Classifier', 'Accuracy', 'F1 Score'])\n",
    "\n",
    "# Loop through each classifier\n",
    "for classifier, classifier_name in zip(classifiers, classifier_names):\n",
    "    # Train the classifier\n",
    "    classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = classifier.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Append results to the DataFrame\n",
    "    results_df = results_df.append({'Classifier': classifier_name, 'Accuracy': accuracy, 'F1 Score': f1,'Precision': precision, 'Recall': recall}, ignore_index=True)\n",
    "\n",
    "# Display the results and name of dataset\n",
    "print(f\"Dataset Name: {dataset_name}\")\n",
    "print()\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63977bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
